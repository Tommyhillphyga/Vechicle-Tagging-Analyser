{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "xw-0G16Srodn",
        "outputId": "2b3ca2e0-bd5f-4c13-f455-da625140db6e"
      },
      "outputs": [],
      "source": [
        "## Connect Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount = True)\n",
        "\n",
        "# data_path = \"/content/gdrive/MyDrive/Trope 1 V2\"\n",
        "data_path = \"/content/gdrive/MyDrive/Avzdax/Data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDDsHCpv59kk",
        "outputId": "177eed46-fdac-4032-9c8f-f5495295d50b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WinError 3] The system cannot find the path specified: '/content/gdrive/MyDrive/Avzdax/Data'\n",
            "c:\\Users\\USER\\Desktop\\box\\AVZDAX\\Vechicle-Tagging-Analyser\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/Avzdax/Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjfmS1lgt9Mv",
        "outputId": "92571ea1-818b-42e6-f4d9-6e54d6571e62"
      },
      "outputs": [],
      "source": [
        "!pip install face-recognition\n",
        "!pip install keras-facenet mtcnn\n",
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EiGekRSh4_8",
        "outputId": "dcd48c7a-7898-430f-b5c1-659d52b0dc30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --quiet ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdDFI0fMt9LN",
        "outputId": "bdac724d-dd7a-4fd7-a891-b274571ad24f"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcNiEoszu5oS",
        "outputId": "66ca6ba1-70db-403b-a851-5cbe20a20494"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.listdir(f\"{data_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2TU_U_ZsgZh"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Vehicle-Driver Matching Tester for Colab\n",
        "\n",
        "Standalone class to test vehicle-driver matching logic without Redis/streaming infrastructure.\n",
        "Takes batch of entry and exit frames, clusters vehicles, matches drivers, creates alert videos.\n",
        "\n",
        "Usage in Colab:\n",
        "    from vehicle_driver_matcher_tester import VehicleDriverMatcherTester\n",
        "\n",
        "    tester = VehicleDriverMatcherTester(\n",
        "        entry_frames_path='./entry_frames',\n",
        "        exit_frames_path='./exit_frames'\n",
        "    )\n",
        "\n",
        "    results = tester.run_analysis()\n",
        "\"\"\"\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Tuple, Optional, Any\n",
        "from dataclasses import dataclass, field\n",
        "from collections import defaultdict\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import mediapipe as mp\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class VehicleSnapshot:\n",
        "    \"\"\"Single vehicle detection snapshot.\"\"\"\n",
        "    vehicle_id: str\n",
        "    frame_path: str\n",
        "    frame: np.ndarray\n",
        "    vehicle_crop: np.ndarray\n",
        "    driver_crops: List[np.ndarray]\n",
        "    bbox: Tuple[int, int, int, int]\n",
        "    timestamp: float\n",
        "    is_entry: bool\n",
        "    vehicle_embedding: Optional[np.ndarray] = None\n",
        "    driver_embedding: Optional[np.ndarray] = None\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class VehicleCluster:\n",
        "    \"\"\"Clustered vehicle with all its frames.\"\"\"\n",
        "    cluster_id: str\n",
        "    snapshots: List[VehicleSnapshot] = field(default_factory=list)\n",
        "    vehicle_embedding: Optional[np.ndarray] = None\n",
        "    driver_embedding: Optional[np.ndarray] = None\n",
        "    is_entry: bool = True\n",
        "\n",
        "    def add_snapshot(self, snapshot: VehicleSnapshot):\n",
        "        self.snapshots.append(snapshot)\n",
        "\n",
        "    def compute_embeddings(self):\n",
        "        \"\"\"Compute average embeddings from all snapshots.\"\"\"\n",
        "        if not self.snapshots:\n",
        "            return\n",
        "\n",
        "        # Vehicle embeddings\n",
        "        vehicle_embs = [s.vehicle_embedding for s in self.snapshots if s.vehicle_embedding is not None]\n",
        "        if vehicle_embs:\n",
        "            self.vehicle_embedding = np.mean(vehicle_embs, axis=0)\n",
        "            self.vehicle_embedding /= (np.linalg.norm(self.vehicle_embedding) + 1e-8)\n",
        "\n",
        "        # Driver embeddings\n",
        "        driver_embs = [s.driver_embedding for s in self.snapshots if s.driver_embedding is not None]\n",
        "        if driver_embs:\n",
        "            self.driver_embedding = np.mean(driver_embs, axis=0)\n",
        "            self.driver_embedding /= (np.linalg.norm(self.driver_embedding) + 1e-8)\n",
        "\n",
        "\n",
        "class VehicleDriverMatcherTester:\n",
        "    \"\"\"\n",
        "    Standalone tester for vehicle-driver matching logic.\n",
        "    No Redis, no streaming - pure batch processing for testing.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        entry_frames_path: str,\n",
        "        exit_frames_path: str,\n",
        "        output_path: str = './output',\n",
        "        # Detection parameters\n",
        "        vehicle_model_path: str = 'yolov8m.pt',\n",
        "        face_model_path: Optional[str] = f\"{data_path}/yolov8s-face.pt\",\n",
        "        reid_model_path: str = f\"{data_path}/model/net_19.pth\",\n",
        "        opts_config_path: str = f\"{data_path}/model/opts.yaml\",\n",
        "        # Clustering parameters\n",
        "        vehicle_similarity_threshold: float = 0.7,\n",
        "        # Matching parameters\n",
        "        driver_similarity_threshold: float = 0.6,\n",
        "        overall_match_threshold: float = 0.5,\n",
        "        # Video parameters\n",
        "        video_fps: int = 10,\n",
        "        verbose: bool = True\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize tester\n",
        "\n",
        "        Args:\n",
        "            entry_frames_path: Directory with entry frames (images)\n",
        "            exit_frames_path: Directory with exit frames (images)\n",
        "            output_path: Where to save alert videos and logs\n",
        "            vehicle_model_path: Path to YOLO vehicle detection model\n",
        "            face_model_path: Path to YOLO face detection model (optional)\n",
        "            vehicle_similarity_threshold: Threshold for clustering vehicles\n",
        "            driver_similarity_threshold: Threshold for matching drivers\n",
        "            overall_match_threshold: Overall threshold for match/mismatch\n",
        "            video_fps: FPS for alert videos\n",
        "            verbose: Print detailed logs\n",
        "        \"\"\"\n",
        "        self.entry_frames_path = Path(entry_frames_path)\n",
        "        self.exit_frames_path = Path(exit_frames_path)\n",
        "        self.output_path = Path(output_path)\n",
        "        self.output_path.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "        self.vehicle_similarity_threshold = vehicle_similarity_threshold\n",
        "        self.driver_similarity_threshold = driver_similarity_threshold\n",
        "        self.overall_match_threshold = overall_match_threshold\n",
        "        self.video_fps = video_fps\n",
        "        self.verbose = verbose\n",
        "\n",
        "        # Load models\n",
        "        self._log(\"=\" * 80)\n",
        "        self._log(\"INITIALIZING VEHICLE-DRIVER MATCHER TESTER\")\n",
        "        self._log(\"=\" * 80)\n",
        "\n",
        "        from ultralytics import YOLO\n",
        "        self._log(f\"Loading vehicle detector: {vehicle_model_path}\")\n",
        "        self.vehicle_detector = YOLO(vehicle_model_path)\n",
        "\n",
        "        # Face detection with fallback\n",
        "        self.face_detector = None\n",
        "\n",
        "\n",
        "        self.face_recognition = None\n",
        "\n",
        "        try:\n",
        "          from keras_facenet import FaceNet\n",
        "          self.facenet_emb = FaceNet()\n",
        "        except:\n",
        "           self._log(\"FaceNet not installed\")\n",
        "\n",
        "        # try:\n",
        "        #   from model.load_reid_model import load_model_from_opts\n",
        "        #   self.vehicle_reid = load_model_from_opts(opts_config_path, ckpt=reid_model_path, remove_classifier=True)\n",
        "        # except:\n",
        "        #     self._log(\"‚ö†Ô∏è  Error with loading Vehicle REID Model\")\n",
        "        from model.load_reid_model import load_model_from_opts\n",
        "        self.vehicle_reid = load_model_from_opts(opts_config_path, ckpt=reid_model_path, remove_classifier=True)\n",
        "\n",
        "        import os\n",
        "        try:\n",
        "            # Force CPU mode to avoid CUDA driver issues\n",
        "            import os\n",
        "            # os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
        "\n",
        "            import face_recognition\n",
        "            self.face_recognition = face_recognition\n",
        "            self._log(\"‚úÖ face_recognition (dlib) loaded as fallback [CPU mode]\")\n",
        "        except ImportError:\n",
        "            self._log(\"‚ö†Ô∏è  face_recognition not installed\")\n",
        "            self._log(\"     Install with: pip install face-recognition\")\n",
        "        except RuntimeError as e:\n",
        "            if \"CUDA\" in str(e) or \"cuda\" in str(e).lower():\n",
        "                self._log(\"‚ö†Ô∏è  CUDA error with face_recognition - will use YOLO only\")\n",
        "                self._log(f\"     {str(e)[:80]}...\")\n",
        "            else:\n",
        "                raise\n",
        "        except Exception as e:\n",
        "            self._log(f\"‚ö†Ô∏è  Could not load face_recognition: {type(e).__name__}\")\n",
        "            self._log(f\"     {str(e)[:80]}...\")\n",
        "\n",
        "        # Ultimate fallback: OpenCV Haar Cascade (lightweight, no dependencies)\n",
        "        self.opencv_face_cascade = None\n",
        "        if self.face_recognition is None and self.face_detector is None:\n",
        "            try:\n",
        "                self.opencv_face_cascade = cv2.CascadeClassifier(\n",
        "                    cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
        "                )\n",
        "                self._log(\"‚úÖ OpenCV Haar Cascade loaded as fallback (basic detection)\")\n",
        "            except Exception as e:\n",
        "                self._log(f\"‚ö†Ô∏è  No face detection available: {e}\")\n",
        "                self._log(\"     Face detection will be limited\")\n",
        "\n",
        "        # Statistics\n",
        "        self.stats = {\n",
        "            'entry_frames_processed': 0,\n",
        "            'exit_frames_processed': 0,\n",
        "            'entry_vehicles_detected': 0,\n",
        "            'exit_vehicles_detected': 0,\n",
        "            'entry_clusters': 0,\n",
        "            'exit_clusters': 0,\n",
        "            'matches_found': 0,\n",
        "            'mismatches_detected': 0,\n",
        "            'no_match_found': 0\n",
        "        }\n",
        "\n",
        "        self._log(\"‚úÖ Initialization complete\\n\")\n",
        "\n",
        "    def _log(self, message: str):\n",
        "        \"\"\"Print log message if verbose.\"\"\"\n",
        "        if self.verbose:\n",
        "            print(message)\n",
        "\n",
        "    # ==================== MAIN PIPELINE ====================\n",
        "\n",
        "    def run_analysis(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Run complete analysis pipeline.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with results and statistics\n",
        "        \"\"\"\n",
        "        self._log(\"\\n\" + \"=\" * 80)\n",
        "        self._log(\"STARTING ANALYSIS PIPELINE\")\n",
        "        self._log(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "        # Step 1: Load and process entry frames\n",
        "        self._log(\"üì• STEP 1: Processing entry frames...\")\n",
        "        entry_snapshots = self._process_frames_batch(self.entry_frames_path, is_entry=True)\n",
        "        self.stats['entry_frames_processed'] = len(list(self.entry_frames_path.glob('*.jpg'))) + len(list(self.entry_frames_path.glob('*.png')))\n",
        "        self.stats['entry_vehicles_detected'] = len(entry_snapshots)\n",
        "        self._log(f\"   Found {len(entry_snapshots)} vehicle snapshots in entry frames\\n\")\n",
        "\n",
        "        # Step 2: Load and process exit frames\n",
        "        self._log(\"üì§ STEP 2: Processing exit frames...\")\n",
        "        exit_snapshots = self._process_frames_batch(self.exit_frames_path, is_entry=False)\n",
        "        self.stats['exit_frames_processed'] = len(list(self.exit_frames_path.glob('*.jpg'))) + len(list(self.exit_frames_path.glob('*.png')))\n",
        "        self.stats['exit_vehicles_detected'] = len(exit_snapshots)\n",
        "        self._log(f\"   Found {len(exit_snapshots)} vehicle snapshots in exit frames\\n\")\n",
        "\n",
        "        # Step 3: Cluster entry vehicles\n",
        "        self._log(\"üîó STEP 3: Clustering entry vehicles...\")\n",
        "        entry_clusters = self.cluster_vehicles_large_batch(entry_snapshots)\n",
        "        self.stats['entry_clusters'] = len(entry_clusters)\n",
        "        self._log(f\"   Created {len(entry_clusters)} entry vehicle clusters\\n\")\n",
        "\n",
        "        # Step 4: Cluster exit vehicles\n",
        "        self._log(\"üîó STEP 4: Clustering exit vehicles...\")\n",
        "        exit_clusters = self.cluster_vehicles_large_batch(exit_snapshots)\n",
        "        self.stats['exit_clusters'] = len(exit_clusters)\n",
        "        self._log(f\"   Created {len(exit_clusters)} exit vehicle clusters\\n\")\n",
        "\n",
        "        # Step 5: Match vehicles and verify drivers\n",
        "        self._log(\"üîç STEP 5: Matching vehicles and verifying drivers...\")\n",
        "        match_results = self._match_and_verify(entry_clusters, exit_clusters)\n",
        "        self._log(f\"   Processed {len(match_results)} exit vehicles\\n\")\n",
        "\n",
        "        # Step 6: Generate summary\n",
        "        self._log(\"=\" * 80)\n",
        "        self._log(\"ANALYSIS COMPLETE\")\n",
        "        self._log(\"=\" * 80)\n",
        "        self._print_summary()\n",
        "\n",
        "        return {\n",
        "            'entry_clusters': entry_clusters,\n",
        "            'exit_clusters': exit_clusters,\n",
        "            'match_results': match_results,\n",
        "            'stats': self.stats\n",
        "        }\n",
        "\n",
        "    # ==================== FRAME PROCESSING ====================\n",
        "\n",
        "    def _process_frames_batch(self, frames_path: Path, is_entry: bool) -> List[VehicleSnapshot]:\n",
        "        \"\"\"\n",
        "        Process all frames in a directory.\n",
        "\n",
        "        Returns:\n",
        "            List of VehicleSnapshot objects\n",
        "        \"\"\"\n",
        "        snapshots = []\n",
        "\n",
        "        # Get all image files\n",
        "        image_files = sorted(\n",
        "            list(frames_path.glob('*.jpg')) +\n",
        "            list(frames_path.glob('*.png')) +\n",
        "            list(frames_path.glob('*.jpeg'))\n",
        "        )\n",
        "\n",
        "        if not image_files:\n",
        "            self._log(f\"   ‚ö†Ô∏è  No images found in {frames_path}\")\n",
        "            return snapshots\n",
        "\n",
        "        self._log(f\"   Processing {len(image_files)} images...\")\n",
        "\n",
        "        for img_path in image_files:\n",
        "            try:\n",
        "                # Load frame\n",
        "                frame = cv2.imread(str(img_path))\n",
        "                if frame is None:\n",
        "                    self._log(f\"   ‚ö†Ô∏è  Failed to load: {img_path.name}\")\n",
        "                    continue\n",
        "\n",
        "                # Detect vehicles\n",
        "                vehicles = self._detect_vehicles(frame)\n",
        "\n",
        "                if not vehicles:\n",
        "                    self._log(f\"   ‚ÑπÔ∏è  No vehicles in: {img_path.name}\")\n",
        "                    continue\n",
        "\n",
        "                # Process each vehicle\n",
        "                for vehicle in vehicles:\n",
        "                    bbox = vehicle['bbox']\n",
        "                    x1, y1, x2, y2 = bbox\n",
        "\n",
        "                    # Crop vehicle\n",
        "                    vehicle_crop = frame[y1:y2, x1:x2]\n",
        "                    if vehicle_crop.size == 0:\n",
        "                        continue\n",
        "\n",
        "                    # Detect driver faces\n",
        "                    driver_crops = self._detect_driver_in_vehicle(frame, bbox)\n",
        "\n",
        "                    if not driver_crops:\n",
        "                        self._log(f\"   ‚ÑπÔ∏è  No driver face in vehicle from {img_path.name}\")\n",
        "                        continue\n",
        "\n",
        "                    # Extract embeddings\n",
        "                    vehicle_emb = self._extract_vehicle_embedding(vehicle_crop)\n",
        "                    driver_emb = self._extract_driver_embedding(driver_crops)   #potential error introduced here if you find more than one person in the vehicle.\n",
        "                                                                                # The search region is looking at both left and right side of the car.\n",
        "                                                                                # At entry point and exit point, we should only search the right side of the car as the perfective doesn't change.\n",
        "\n",
        "                    # Create snapshot\n",
        "                    snapshot = VehicleSnapshot(\n",
        "                        vehicle_id=str(uuid.uuid4())[:8],\n",
        "                        frame_path=str(img_path),\n",
        "                        frame=frame.copy(),\n",
        "                        vehicle_crop=vehicle_crop,\n",
        "                        driver_crops=driver_crops,\n",
        "                        bbox=bbox,\n",
        "                        timestamp=os.path.getmtime(img_path),\n",
        "                        is_entry=is_entry,\n",
        "                        vehicle_embedding=vehicle_emb,\n",
        "                        driver_embedding=driver_emb\n",
        "                    )\n",
        "\n",
        "                    snapshots.append(snapshot)\n",
        "                    self._log(f\"   ‚úÖ Vehicle snapshot from {img_path.name}: {len(driver_crops)} faces detected\")\n",
        "\n",
        "            except Exception as e:\n",
        "                self._log(f\"   ‚ùå Error processing {img_path.name}: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                continue\n",
        "\n",
        "        return snapshots\n",
        "\n",
        "    def _detect_vehicles(self, frame: np.ndarray) -> List[Dict]:\n",
        "        \"\"\"Detect vehicles in frame.\"\"\"\n",
        "        try:\n",
        "            results = self.vehicle_detector(\n",
        "                frame,\n",
        "                verbose=False,\n",
        "                classes=[2, 3, 5, 7],  # car, motorcycle, bus, truck\n",
        "                conf=0.5\n",
        "            )\n",
        "\n",
        "            vehicles = []\n",
        "            for result in results:\n",
        "                if not hasattr(result, 'boxes') or result.boxes is None:\n",
        "                    continue\n",
        "\n",
        "                for box in result.boxes:\n",
        "                    try:\n",
        "                        x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
        "                        if x2 <= x1 or y2 <= y1:\n",
        "                            continue\n",
        "\n",
        "                        vehicles.append({\n",
        "                            'bbox': (x1, y1, x2, y2),\n",
        "                            'confidence': float(box.conf[0])\n",
        "                        })\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "            return vehicles\n",
        "\n",
        "        except Exception as e:\n",
        "            self._log(f\"   ‚ùå Vehicle detection error: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _detect_driver_in_vehicle (\n",
        "        self,\n",
        "        frame: np.ndarray,\n",
        "        vehicle_bbox: Tuple[int, int, int, int]\n",
        "    ) -> List[np.ndarray]:\n",
        "        \"\"\"\n",
        "        Detect driver faces in vehicle using multi-region strategy.\n",
        "        \"\"\"\n",
        "        x1, y1, x2, y2 = vehicle_bbox\n",
        "        vehicle_width = x2 - x1\n",
        "        vehicle_height = y2 - y1\n",
        "\n",
        "        # Try multiple regions\n",
        "        search_regions = [\n",
        "            # Left upper (driver side left-hand traffic)\n",
        "            frame[y1:int(y1 + vehicle_height * 0.6), x1:int(x1 + vehicle_width * 0.6)],\n",
        "            # Right upper (driver side right-hand traffic)\n",
        "            frame[y1:int(y1 + vehicle_height * 0.6), int(x1 + vehicle_width * 0.4):x2],\n",
        "            # Center upper\n",
        "            frame[y1:int(y1 + vehicle_height * 0.5), int(x1 + vehicle_width * 0.25):int(x2 - vehicle_width * 0.25)],\n",
        "            Full vehicle\n",
        "            frame[y1:y2, x1:x2]\n",
        "        ]\n",
        "\n",
        "        for region in search_regions:\n",
        "            if region.size == 0:\n",
        "                continue\n",
        "\n",
        "            faces = self._detect_faces_in_region(region)\n",
        "            if len(faces) > 0:\n",
        "                return faces\n",
        "\n",
        "        return []\n",
        "\n",
        "    def _detect_faces_in_region(self, region: np.ndarray) -> List[np.ndarray]:\n",
        "        \"\"\"Detect faces in a region with YOLO + dlib + OpenCV fallback.\"\"\"\n",
        "        # Try YOLO first\n",
        "        if self.face_detector is not None:\n",
        "            try:\n",
        "                results = self.face_detector(region, verbose=False, conf=0.3)\n",
        "\n",
        "                face_crops = []\n",
        "                for result in results:\n",
        "                    if not hasattr(result, 'boxes') or result.boxes is None:\n",
        "                        continue\n",
        "\n",
        "                    for box in result.boxes:\n",
        "                        try:\n",
        "                            coords = box.xyxy[0].cpu().numpy() if hasattr(box.xyxy[0], 'cpu') else box.xyxy[0]\n",
        "                            x1, y1, x2, y2 = map(int, coords)\n",
        "\n",
        "                            if x2 <= x1 or y2 <= y1:\n",
        "                                continue\n",
        "\n",
        "                            h, w = region.shape[:2]\n",
        "                            x1, y1 = max(0, x1), max(0, y1)\n",
        "                            x2, y2 = min(w, x2), min(h, y2)\n",
        "\n",
        "                            face_crop = region[y1:y2, x1:x2]\n",
        "                            if face_crop.size > 0 and self._are_eyes_and_nose_visible_from_crop(face_crop):\n",
        "                                face_crops.append(face_crop)\n",
        "                        except:\n",
        "                            continue\n",
        "\n",
        "                if len(face_crops) > 0:\n",
        "                    return face_crops\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Fallback to dlib\n",
        "        if self.face_recognition is not None:\n",
        "            try:\n",
        "                rgb_region = cv2.cvtColor(region, cv2.COLOR_BGR2RGB)\n",
        "                face_locations = self.face_recognition.face_locations(\n",
        "                    rgb_region,\n",
        "                    model=\"hog\",\n",
        "                    number_of_times_to_upsample=0\n",
        "                )\n",
        "\n",
        "                face_crops = []\n",
        "                for (top, right, bottom, left) in face_locations:\n",
        "                    face_crop = region[top:bottom, left:right]\n",
        "                    if face_crop.size > 0 and self._check_face_quality(face_crop):\n",
        "                        face_crops.append(face_crop)\n",
        "\n",
        "                if len(face_crops) > 0:\n",
        "                    return face_crops\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Ultimate fallback: OpenCV Haar Cascade\n",
        "        if self.opencv_face_cascade is not None:\n",
        "            try:\n",
        "                gray = cv2.cvtColor(region, cv2.COLOR_BGR2GRAY)\n",
        "                faces = self.opencv_face_cascade.detectMultiScale(\n",
        "                    gray,\n",
        "                    scaleFactor=1.1,\n",
        "                    minNeighbors=5,\n",
        "                    minSize=(30, 30)\n",
        "                )\n",
        "\n",
        "                face_crops = []\n",
        "                for (x, y, w, h) in faces:\n",
        "                    face_crop = region[y:y+h, x:x+w]\n",
        "                    if face_crop.size > 0 and self._check_face_quality(face_crop):\n",
        "                        face_crops.append(face_crop)\n",
        "\n",
        "                return face_crops\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        return []\n",
        "\n",
        "    def _check_face_quality(self, face_crop: np.ndarray) -> bool:\n",
        "        \"\"\"Basic face quality check.\"\"\"\n",
        "        try:\n",
        "            h, w = face_crop.shape[:2]\n",
        "            if h < 20 or w < 20:\n",
        "                return False\n",
        "\n",
        "            gray = cv2.cvtColor(face_crop, cv2.COLOR_BGR2GRAY) if len(face_crop.shape) == 3 else face_crop\n",
        "\n",
        "            # Check std deviation (reject uniform regions)\n",
        "            if np.std(gray) < 10:\n",
        "                return False\n",
        "\n",
        "            # Check brightness\n",
        "            brightness = np.mean(gray)\n",
        "            if brightness < 15 or brightness > 240:\n",
        "                return False\n",
        "\n",
        "            return True\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    def _are_eyes_and_nose_visible_from_crop(self, face_crop, visibility_threshold=0.5, static_image_mode=True ):\n",
        "\n",
        "      \"\"\"\n",
        "      Detect face landmarks using MediaPipe and check if both eyes and nose are visible.\n",
        "      \"\"\"\n",
        "      try:\n",
        "        mp_face_mesh = mp.solutions.face_mesh\n",
        "      except:\n",
        "        print(\"Error loading mediapipe\")\n",
        "\n",
        "      if face_crop is None or face_crop.size == 0:\n",
        "          return False\n",
        "\n",
        "      h, w, _ = face_crop.shape\n",
        "\n",
        "      face_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "      with mp_face_mesh.FaceMesh(\n",
        "          static_image_mode=static_image_mode,\n",
        "          max_num_faces=1,\n",
        "          refine_landmarks=True,\n",
        "          min_detection_confidence=0.5,\n",
        "          min_tracking_confidence=0.5\n",
        "      ) as face_mesh:\n",
        "\n",
        "          results = face_mesh.process(face_rgb)\n",
        "\n",
        "          if not results.multi_face_landmarks:\n",
        "              return False\n",
        "\n",
        "          face_landmarks = results.multi_face_landmarks[0]\n",
        "\n",
        "          # Landmark indices\n",
        "          LEFT_EYE = 33\n",
        "          RIGHT_EYE = 263\n",
        "          NOSE = 1\n",
        "\n",
        "          for idx in [LEFT_EYE, RIGHT_EYE, NOSE]:\n",
        "              lm = face_landmarks.landmark[idx]\n",
        "\n",
        "              # Normalized coordinate check\n",
        "              if not (0.0 <= lm.x <= 1.0 and 0.0 <= lm.y <= 1.0):\n",
        "                  return False\n",
        "\n",
        "              # Pixel coordinate check\n",
        "              x_px = int(lm.x * w)\n",
        "              y_px = int(lm.y * h)\n",
        "\n",
        "              if x_px < 0 or x_px >= w or y_px < 0 or y_px >= h:\n",
        "                  return False\n",
        "\n",
        "              #   visibility / presence checks\n",
        "              if hasattr(lm, \"visibility\") and lm.visibility < visibility_threshold:\n",
        "                  return False\n",
        "\n",
        "              if hasattr(lm, \"presence\") and lm.presence < visibility_threshold:\n",
        "                  return False\n",
        "\n",
        "          return True\n",
        "\n",
        "    # ==================== EMBEDDING EXTRACTION ====================\n",
        "    def _extract_driver_embedding(self, driver_crops: List[np.ndarray])-> np.ndarray:\n",
        "      try:\n",
        "        if not driver_crops:\n",
        "          return np.zeros(512, dtype=np.float64)\n",
        "        embeddings_list = []\n",
        "\n",
        "        for face in driver_crops:\n",
        "          print(f\"face shape: {face.shape}\")\n",
        "          face = cv2.resize(face, (128, 128))\n",
        "          face = face.astype('float64')\n",
        "          face = np.expand_dims(face, axis=0)\n",
        "          embedding = self.facenet_emb.embeddings(face)\n",
        "          embeddings_list.append(embedding[0])\n",
        "\n",
        "        # Average all embeddings\n",
        "        avg_embedding = np.mean(embeddings_list, axis=0)\n",
        "        avg_embedding = avg_embedding / (np.linalg.norm(avg_embedding))\n",
        "\n",
        "        return avg_embedding.astype(np.float64)\n",
        "\n",
        "      except Exception as e:\n",
        "            self._log(f\"   ‚ùå Driver embedding error: {e}\")\n",
        "            return np.zeros(512, dtype=np.float64)\n",
        "\n",
        "\n",
        "    def _extract_vehicle_embedding(self, vehicle_crop: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Extract vehicle ReID embedding using color histogram.\"\"\"\n",
        "        device = \"cuda\"\n",
        "        try:\n",
        "            # Resize\n",
        "            resized = cv2.resize(cv2.cvtColor(vehicle_crop, cv2.COLOR_BGR2RGB), (224, 224))\n",
        "            resized = resized.transpose(2, 0, 1)\n",
        "            resized = torch.from_numpy(resized).float().unsqueeze(0).to(device)\n",
        "\n",
        "            try:\n",
        "                model = self.vehicle_reid.eval().to(device)\n",
        "                vehicle_embedding = model(resized)\n",
        "                vehicle_embedding = vehicle_embedding.detach().cpu().numpy()\n",
        "                vehicle_embedding = vehicle_embedding / (np.linalg.norm(vehicle_embedding))\n",
        "\n",
        "            except ImportError:\n",
        "               vehicle_embedding = np.array([])\n",
        "\n",
        "            return vehicle_embedding.astype(np.float64)\n",
        "\n",
        "        except Exception as e:\n",
        "            self._log(f\"   ‚ùå Vehicle embedding error: {e}\")\n",
        "            return np.zeros(512, dtype=np.float64)\n",
        "\n",
        "\n",
        "\n",
        "    # ==================== CLUSTERING ====================\n",
        "\n",
        "    def cluster_vehicles_large_batch(self, snapshots: List[VehicleSnapshot]) -> List[VehicleCluster]:\n",
        "\n",
        "      if not snapshots:\n",
        "          return []\n",
        "\n",
        "      clusters: List[VehicleCluster] = []\n",
        "      centroids: List[np.ndarray] = []  # each is (D,)\n",
        "\n",
        "      for snapshot in snapshots:\n",
        "          emb = snapshot.vehicle_embedding  # already normalized\n",
        "\n",
        "          # First cluster\n",
        "          if not centroids:\n",
        "              cluster = VehicleCluster(\n",
        "                  cluster_id=f\"{snapshot.vehicle_id}\",\n",
        "                  is_entry=snapshot.is_entry\n",
        "              )\n",
        "              cluster.add_snapshot(snapshot)\n",
        "              cluster.compute_embeddings()\n",
        "\n",
        "              clusters.append(cluster)\n",
        "              centroids.append(cluster.vehicle_embedding)  # normalized\n",
        "              continue\n",
        "\n",
        "          # Stack centroids for vectorized similarity\n",
        "          centroid_matrix = np.vstack(centroids)  # (K, D)\n",
        "          similarities = self.cosine_similarity_to_centroids(\n",
        "              emb,\n",
        "              centroid_matrix\n",
        "          )\n",
        "\n",
        "          best_idx = int(np.argmax(similarities))\n",
        "          best_score = similarities[best_idx]\n",
        "\n",
        "          if best_score >= self.vehicle_similarity_threshold:\n",
        "              # Assign to existing cluster\n",
        "              cluster = clusters[best_idx]\n",
        "              cluster.add_snapshot(snapshot)\n",
        "\n",
        "              # Incremental centroid update (still normalized later)\n",
        "              n = len(cluster.snapshots)\n",
        "              updated_centroid = (\n",
        "                  (centroids[best_idx] * (n - 1) + emb) / n\n",
        "              )\n",
        "\n",
        "              #re-normalize centroid\n",
        "              centroids[best_idx] = updated_centroid / np.linalg.norm(updated_centroid)\n",
        "\n",
        "          else:\n",
        "              # Create new cluster\n",
        "              cluster = VehicleCluster(\n",
        "                  cluster_id=f\"{snapshot.vehicle_id}\",\n",
        "                  is_entry=snapshot.is_entry\n",
        "              )\n",
        "              cluster.add_snapshot(snapshot)\n",
        "              cluster.compute_embeddings()\n",
        "\n",
        "              clusters.append(cluster)\n",
        "              centroids.append(cluster.vehicle_embedding)  # already normalized\n",
        "\n",
        "              self._log(f\"   Cluster {cluster.cluster_id}: {len(cluster.snapshots)} snapshots\")\n",
        "\n",
        "      return clusters\n",
        "\n",
        "\n",
        "    # ==================== MATCHING & VERIFICATION ====================\n",
        "\n",
        "    def _match_and_verify(\n",
        "        self,\n",
        "        entry_clusters: List[VehicleCluster],\n",
        "        exit_clusters: List[VehicleCluster]\n",
        "    ) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Match exit vehicles to entry vehicles and verify drivers.\n",
        "        \"\"\"\n",
        "        results = []\n",
        "\n",
        "        for exit_cluster in exit_clusters:\n",
        "            self._log(f\"\\nüöó Processing exit vehicle: {exit_cluster.cluster_id}\")\n",
        "\n",
        "            # Find matching entry vehicle\n",
        "            best_match = None\n",
        "            best_driver_score = 0.0\n",
        "\n",
        "            for entry_cluster in entry_clusters:\n",
        "\n",
        "                driver_score = self.compute_cosine_similarity(\n",
        "                    exit_cluster.driver_embedding,\n",
        "                    entry_cluster.driver_embedding\n",
        "                )\n",
        "                print(f\"driver_score: {driver_score}\")\n",
        "\n",
        "                if driver_score > best_driver_score:\n",
        "                    best_driver_score = driver_score\n",
        "                    best_match = entry_cluster\n",
        "\n",
        "            if best_match is None or best_driver_score < self.driver_similarity_threshold:\n",
        "                self._log(f\"   ‚ö†Ô∏è  No matching entry driver found (best score: {best_driver_score:.3f})\")\n",
        "                self.stats['no_match_found'] += 1\n",
        "\n",
        "                results.append({\n",
        "                    'exit_cluster': exit_cluster,\n",
        "                    'entry_cluster': None,\n",
        "                    'vehicle_score': best_driver_score,\n",
        "                    'driver_score': 0.0,\n",
        "                    'overall_score': 0.0,\n",
        "                    'is_match': False,\n",
        "                    'reason': 'no_entry_driver_found'\n",
        "                })\n",
        "                continue\n",
        "\n",
        "            self._log(f\"   ‚úÖ Matched to entry driver: {best_match.cluster_id} (score: {best_driver_score:.3f})\")\n",
        "\n",
        "            # Verify vehicle\n",
        "            vehicle_score = self.compute_cosine_similarity(\n",
        "                exit_cluster.vehicle_embedding,\n",
        "                best_match.vehicle_embedding\n",
        "            )\n",
        "\n",
        "            # Calculate overall score\n",
        "            overall_score = (0.4 * best_driver_score) + (0.6 * vehicle_score)\n",
        "\n",
        "            is_match = (\n",
        "                driver_score >= self.driver_similarity_threshold and\n",
        "                overall_score >= self.overall_match_threshold\n",
        "            )\n",
        "\n",
        "            self._log(f\"   vehicle similarity: {vehicle_score:.3f}\")\n",
        "            self._log(f\"   Overall score: {overall_score:.3f}\")\n",
        "\n",
        "            if is_match:\n",
        "                self._log(f\"   ‚úÖ MATCH: Same driver\")\n",
        "                self.stats['matches_found'] += 1\n",
        "            else:\n",
        "                self._log(f\"   ‚ùå MISMATCH: Different driver!\")\n",
        "                self.stats['mismatches_detected'] += 1\n",
        "\n",
        "                # Create alert video\n",
        "                self._create_mismatch_alert_video(\n",
        "                    entry_cluster=best_match,\n",
        "                    exit_cluster=exit_cluster,\n",
        "                    vehicle_score=vehicle_score,\n",
        "                    driver_score=best_driver_score,\n",
        "                    overall_score=overall_score\n",
        "                )\n",
        "\n",
        "            results.append({\n",
        "                'exit_cluster': exit_cluster,\n",
        "                'entry_cluster': best_match,\n",
        "                'driver_score': best_driver_score,\n",
        "                'vehicle_score': vehicle_score,\n",
        "                'overall_score': overall_score,\n",
        "                'is_match': is_match,\n",
        "                'reason': 'match' if is_match else 'driver_mismatch'\n",
        "            })\n",
        "\n",
        "        return results\n",
        "\n",
        "    import numpy as np\n",
        "\n",
        "    def cosine_similarity_to_centroids(self, \n",
        "        embedding: np.ndarray,\n",
        "        centroids: np.ndarray\n",
        "    ) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        embedding: (D,)\n",
        "        centroids: (K, D)\n",
        "        returns: (K,)\n",
        "        \"\"\"\n",
        "        if embedding.ndim == 2:\n",
        "          embedding = embedding.squeeze(0)  # (D,)\n",
        "        return np.dot(centroids, embedding)\n",
        "\n",
        "\n",
        "    def compute_cosine_similarity(self, vec1, vec2):\n",
        "      vec1 = vec1.reshape(1,-1)\n",
        "      vec2 = vec2.reshape(1,-1)\n",
        "\n",
        "      similarity = cosine_similarity(vec1, vec2)\n",
        "      return float(similarity[0][0])\n",
        "\n",
        "  \n",
        "\n",
        "    def _print_summary(self):\n",
        "        \"\"\"Print analysis summary.\"\"\"\n",
        "        self._log(\"\\nüìä ANALYSIS SUMMARY:\")\n",
        "        self._log(f\"   Entry frames processed: {self.stats['entry_frames_processed']}\")\n",
        "        self._log(f\"   Exit frames processed: {self.stats['exit_frames_processed']}\")\n",
        "        self._log(f\"   Entry vehicles detected: {self.stats['entry_vehicles_detected']}\")\n",
        "        self._log(f\"   Exit vehicles detected: {self.stats['exit_vehicles_detected']}\")\n",
        "        self._log(f\"   Entry clusters: {self.stats['entry_clusters']}\")\n",
        "        self._log(f\"   Exit clusters: {self.stats['exit_clusters']}\")\n",
        "        self._log(f\"   ‚úÖ Matches found: {self.stats['matches_found']}\")\n",
        "        self._log(f\"   ‚ùå Mismatches detected: {self.stats['mismatches_detected']}\")\n",
        "        self._log(f\"   ‚ö†Ô∏è  No match found: {self.stats['no_match_found']}\")\n",
        "        self._log(f\"\\nüìÅ Output directory: {self.output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxigtJyptSNE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkWMPPbO2AyA",
        "outputId": "c816547f-5315-457c-acfe-8a01f1de48e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "INITIALIZING VEHICLE-DRIVER MATCHER TESTER\n",
            "================================================================================\n",
            "Loading vehicle detector: yolov8m.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/hub.py:335: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/XingangPan/IBN-Net/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "Downloading: \"https://github.com/XingangPan/IBN-Net/releases/download/v1.0/resnet50_ibn_a-d9d0bb7b.pth\" to /root/.cache/torch/hub/checkpoints/resnet50_ibn_a-d9d0bb7b.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97.7M/97.7M [00:01<00:00, 56.3MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ face_recognition (dlib) loaded as fallback [CPU mode]\n",
            "‚úÖ Initialization complete\n",
            "\n",
            "\n",
            "================================================================================\n",
            "STARTING ANALYSIS PIPELINE\n",
            "================================================================================\n",
            "\n",
            "üì• STEP 1: Processing entry frames...\n",
            "   Processing 85 images...\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000011.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000012.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000013.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000014.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000015.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000016.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000017.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000018.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000019.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000020.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000021.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000022.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000023.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000024.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000025.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000026.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000027.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000028.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000029.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000030.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000031.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000032.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000033.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000034.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000035.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000036.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000037.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000038.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000039.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000040.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000041.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000042.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000043.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000044.jpg\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step\n",
            "   ‚úÖ Vehicle snapshot from frame_000045.jpg: 1 faces detected\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000045.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000046.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000046.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000047.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000047.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000048.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000048.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000049.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000049.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000050.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000050.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000051.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000051.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000052.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000052.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000053.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000053.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000054.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000054.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000055.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000055.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000055.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000056.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000056.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000056.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000057.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000057.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000057.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000058.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000058.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000059.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000059.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000060.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000060.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000061.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000061.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000062.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000063.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000064.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000064.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000065.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000066.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000067.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000067.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000068.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000068.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000068.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000069.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000069.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000070.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000070.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000071.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000071.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000071.jpg\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "   ‚úÖ Vehicle snapshot from frame_000072.jpg: 1 faces detected\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000072.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000072.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000073.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000073.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000074.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000074.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000075.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000075.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000076.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000076.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000077.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000077.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000078.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000078.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000079.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000079.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000079.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000080.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000080.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000081.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000081.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000082.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000082.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000082.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000083.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000083.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000084.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000084.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000085.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000085.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000086.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000086.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000087.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000087.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000294.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000294.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000295.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000295.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000296.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000296.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000297.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000297.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000298.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000298.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000299.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000299.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000300.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000300.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000301.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000301.jpg\n",
            "   Found 2 vehicle snapshots in entry frames\n",
            "\n",
            "üì§ STEP 2: Processing exit frames...\n",
            "   Processing 85 images...\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000011.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000012.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000013.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000014.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000015.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000016.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000017.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000018.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000019.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000020.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000021.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000022.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000023.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000024.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000025.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000026.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000027.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000028.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000029.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000030.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000031.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000032.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000033.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000034.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000035.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000036.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000037.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000038.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000039.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000040.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000041.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000042.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000043.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000044.jpg\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "   ‚úÖ Vehicle snapshot from frame_000045.jpg: 1 faces detected\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000045.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000046.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000046.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000047.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000047.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000048.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000048.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000049.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000049.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000050.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000050.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000051.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000051.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000052.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000052.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000053.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000053.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000054.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000054.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000055.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000055.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000055.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000056.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000056.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000056.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000057.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000057.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000057.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000058.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000058.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000059.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000059.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000060.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000060.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000061.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000061.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000062.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000063.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000064.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000064.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000065.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000066.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000067.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000067.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000068.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000068.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000068.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000069.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000069.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000070.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000070.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000071.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000071.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000071.jpg\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "   ‚úÖ Vehicle snapshot from frame_000072.jpg: 1 faces detected\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000072.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000072.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000073.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000073.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000074.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000074.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000075.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000075.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000076.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000076.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000077.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000077.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000078.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000078.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000079.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000079.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000079.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000080.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000080.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000081.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000081.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000082.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000082.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000082.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000083.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000083.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000084.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000084.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000085.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000085.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000086.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000086.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000087.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000087.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000294.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000294.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000295.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000295.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000296.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000296.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000297.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000297.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000298.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000298.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000299.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000299.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000300.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000300.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000301.jpg\n",
            "   ‚ÑπÔ∏è  No driver face in vehicle from frame_000301.jpg\n",
            "   Found 2 vehicle snapshots in exit frames\n",
            "\n",
            "üîó STEP 3: Clustering entry vehicles...\n",
            "   Cluster e376af5f: 1 snapshots\n",
            "   Cluster 79e55e57: 1 snapshots\n",
            "   Created 2 entry vehicle clusters\n",
            "\n",
            "üîó STEP 4: Clustering exit vehicles...\n",
            "   Cluster 740e0dc2: 1 snapshots\n",
            "   Cluster 35b78336: 1 snapshots\n",
            "   Created 2 exit vehicle clusters\n",
            "\n",
            "üîç STEP 5: Matching vehicles and verifying drivers...\n",
            "\n",
            "üöó Processing exit vehicle: 740e0dc2\n",
            "vehicle_score: 1.0\n",
            "vehicle_score: 0.9997501276948911\n",
            "   ‚úÖ Matched to entry vehicle: e376af5f (score: 1.000)\n",
            "   Driver similarity: 1.000\n",
            "   Overall score: 1.000\n",
            "   ‚úÖ MATCH: Same driver\n",
            "\n",
            "üöó Processing exit vehicle: 35b78336\n",
            "vehicle_score: 0.9997501276948911\n",
            "vehicle_score: 1.0000000000000002\n",
            "   ‚úÖ Matched to entry vehicle: 79e55e57 (score: 1.000)\n",
            "   Driver similarity: 1.000\n",
            "   Overall score: 1.000\n",
            "   ‚úÖ MATCH: Same driver\n",
            "   Processed 2 exit vehicles\n",
            "\n",
            "================================================================================\n",
            "ANALYSIS COMPLETE\n",
            "================================================================================\n",
            "\n",
            "üìä ANALYSIS SUMMARY:\n",
            "   Entry frames processed: 85\n",
            "   Exit frames processed: 85\n",
            "   Entry vehicles detected: 2\n",
            "   Exit vehicles detected: 2\n",
            "   Entry clusters: 2\n",
            "   Exit clusters: 2\n",
            "   ‚úÖ Matches found: 2\n",
            "   ‚ùå Mismatches detected: 0\n",
            "   ‚ö†Ô∏è  No match found: 0\n",
            "\n",
            "üìÅ Output directory: output\n"
          ]
        }
      ],
      "source": [
        "tester = VehicleDriverMatcherTester(\n",
        "            entry_frames_path=f\"{data_path}/entry_frames\",\n",
        "            exit_frames_path=f\"{data_path}/exit_frames\",\n",
        "            vehicle_similarity_threshold=0.7,\n",
        "            driver_similarity_threshold=0.6,\n",
        "            overall_match_threshold=0.5\n",
        "        )\n",
        "\n",
        "results = tester.run_analysis()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pOudG6C2AwR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
